# ML_BackPropagation
1) Effects of varying Learning rate (Eta) 2) Effects of varying Lambda (regularization parameter) 3) Effects of varying number of neurons in hidden layer 4) Effects of varying number of hidden layers 5) Effects of varying activation function (sigmoid vs tanh)
